{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"resources/fire.gif\" align=left width=200  style=\"margin-top:0\"> \n",
    "<img src=\"resources/pizza.png\" align=left width=200 style=\"margin-top:0\"> \n",
    "<img src=\"resources/pizzafire.gif\" align=left width=200  style=\"margin-top:0\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pizzafire\n",
    "A multithreaded job queue for distributed neural network tasks. Automates the deployment and termination of many AWS EC2 g2.2xlarge instances appropriately to minimize cost. Executes commands and monitors activity over ssh. \n",
    "\n",
    "This notebook is setup to apply *A Neural Algorithm of Artistic Style (Gatys, Ecker & Bethge, 2015)* to video or very large images.\n",
    "\n",
    "### Style Transfer\n",
    "\n",
    "What if you could take a picture and remix it in the style of another picture? You can! Style Transfer takes one content image and one style image. The result is an image with the global arrangement of the content image and the style/texture of the style image. \n",
    "\n",
    "Read more here https://github.com/jcjohnson/neural-style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "1. Register for AWS: https://aws.amazon.com/\n",
    "\n",
    "2. Install boto3 and configure AWS credentials. Follow these instructions: https://github.com/boto/boto3\n",
    "\n",
    "3. Create a security group in AWS console called \"ssh-http\". \n",
    "        Enable inbound SSH (tcp port 22)\n",
    "        Enable inbound HTTP (tcp port 80)\n",
    "        Enable outbound all traffic. \n",
    "\n",
    "4. Configure parameters of job. See *Configure* and *Jobs* below for examples. \n",
    "\n",
    "5. Run all code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# @author CJ Carr, 2016 \n",
    "# http://github.com/cortexelus/pizzafire\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import threading\n",
    "import boto3\n",
    "from ntpath import basename\n",
    "\n",
    "# Should a particular thread take another job, or terminate?\n",
    "def should_terminate():\n",
    "    # current time + time it would take to process + extra time allotted for shutdown \n",
    "    return time.time() + estimated_process_time + termination_margin >= termination_time\n",
    "\n",
    "# Should all the threads and VMs terminate?\n",
    "def should_terminate_all():\n",
    "    # current time + extra time allotted for shutdown \n",
    "    return time.time() + termination_margin >= termination_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is so we don't have to call flush() everytime we print\n",
    "# See: http://stackoverflow.com/questions/107705/disable-output-buffering\n",
    "class Unbuffered(object):\n",
    "    def __init__(self, stream):\n",
    "        self.stream = stream\n",
    "    def write(self, data):\n",
    "        try: \n",
    "            self.stream.write(data)\n",
    "            self.stream.flush()\n",
    "        except:\n",
    "            # couldn't print to stdout for some reason\n",
    "            # maybe because I switched iPython cells in the middle of it trying to print \n",
    "            # whatever, not that important, don't raise the exception \n",
    "            pass\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.stream, attr)\n",
    "sys.stdout = Unbuffered(sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# style_image = local image whose style we are transferring\n",
    "# content = local image or directory containing individual frames of the video we are processing\n",
    "# directory = True if content is directory, False if content is image\n",
    "def add_to_jobs(style_image, content, directory=False):\n",
    "    if(directory):\n",
    "        files = !ls \"{content}\"\n",
    "        content_directory = content\n",
    "    else:\n",
    "        files = [content]\n",
    "        content_directory = \".\"\n",
    "    # status = incomplete | complete | processing\n",
    "    # last_modified = timestamp of last change to status\n",
    "    # host = public_dns_address of AWS machine\n",
    "    # content = filename of content image to process (directory relative to ipynb file)\n",
    "    # style = filename of style image to process (directory relative to ipynb file)\n",
    "    new_jobs = [{\"status\": \"incomplete\", \"host\": \"\", \"last_modified\": start_time, \"style\": style_image, \"content\": content_directory + \"/\" + f } for f in files]\n",
    "    jobs.extend(new_jobs)\n",
    "    #print jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nanny thread\n",
    "# Terminates all VMs before time limit, just in case \n",
    "def nanny():\n",
    "    global workers, jobs, vm_ids, start_time\n",
    "    time.sleep(30) # wait a bit before thread checking \n",
    "    while True: \n",
    "        #print \"Nanny: Checking threads. . .\"\n",
    "        # check if all jobs are complete\n",
    "        if all_jobs_complete():\n",
    "            print \"All jobs complete\"\n",
    "            break\n",
    "        # check if time limit is really close (within terminate_margin)\n",
    "        if should_terminate_all():\n",
    "            print \"Nanny: The hour draws near...\"\n",
    "            break\n",
    "        # if there is free time to process another job, check for dead threads, restart them\n",
    "        if not should_terminate():\n",
    "            for i in xrange(len(workers)):\n",
    "                thread = workers[i]\n",
    "                if not thread.is_alive():\n",
    "                    # There are still jobs to do, but this thread has terminated\n",
    "                    # Set its jobs to \"incomplete\"\n",
    "                    # TODO ## [job[\"status\"]=\"incomplete\" for job in jobs if job[\"host\"]==]\n",
    "                    # restart thread\n",
    "                    new_thread = threading.Thread(target=worker, args=(i,vm_ids[i],))\n",
    "                    workers[i] = new_thread\n",
    "                    new_thread.start()\n",
    "        time.sleep(1) # wait a sec just to make sure new threads appear alive\n",
    "        # At this point check if all threads have died, if so, end the process early\n",
    "        if reduce(lambda x, y: x and y, [not t.is_alive() for t in workers]):\n",
    "            print \"All workers have finished, although not all jobs were completed\"\n",
    "            break \n",
    "        time.sleep(15)\n",
    "    # Terminate everything \n",
    "    print \"Terminating all VMs...\"\n",
    "    [ec2.Instance(id=vm_id).terminate() for vm_id in vm_ids]\n",
    "    complete = reduce(lambda x, y: x + y, [1 if j[\"status\"] == \"complete\" else 0 for j in jobs ])\n",
    "    incomplete = reduce(lambda x, y: x + y, [1 if j[\"status\"] == \"incomplete\" else 0 for j in jobs ])\n",
    "    processing = reduce(lambda x, y: x + y, [1 if j[\"status\"] == \"processing\" else 0 for j in jobs ])\n",
    "    print \"Complete: %i\\nIncomplete: %i\\nStuck Processing: %i\\n\" % (complete, incomplete, processing)\n",
    "    print \"\\nDone.\"\n",
    "    print \"Took %s minutes\" % ((time.time()-start_time)/60)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# Return true if all jobs are complete\n",
    "def all_jobs_complete():\n",
    "    global jobs\n",
    "    return reduce(lambda x, y: x and y, [j[\"status\"] == \"complete\" for j in jobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Worker thread. Give it an arbitrary worker id i, and the id of an ec2 instance. \n",
    "# 1. Waits for ec2 machine to change to \"running\" state\n",
    "# 2. Looks for available jobs and does them. Repeat.\n",
    "# Terminates when all jobs are done, or if time limit is close. \n",
    "def worker(i, vm_id):\n",
    "    global jobs, jobs_lock, estimated_process_time, shuffle_jobs, vm_ids\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    time.sleep(1)\n",
    "    print 'Worker: %s %s' % (i, vm_id)\n",
    "    time.sleep(5) # sometimes the instance doesn't immediately exist\n",
    "    while ec2.Instance(id=vm_id).state[\"Name\"] != 'running':\n",
    "        print \"%s is still asleep (%s)\" % (i, vm_id)\n",
    "        time.sleep(5)\n",
    "    print \"%s is awake (%s)\" % (i, vm_id)\n",
    "    vm = ec2.Instance(id=vm_id)\n",
    "    host = vm.public_dns_name\n",
    "    \n",
    "    # Look for jobs\n",
    "    while True:\n",
    "        # Should Thread Terminate because of time?\n",
    "        if should_terminate():\n",
    "            print \"The hour draws near. Terminate this VM before amazon charges us another hour. \"\n",
    "            break  \n",
    "            \n",
    "        # Should thread terminate because all jobs are complete?\n",
    "        if all_jobs_complete():\n",
    "            print \"All jobs complete.\"\n",
    "            break\n",
    "            \n",
    "        # Claim a job\n",
    "        while(jobs_lock):\n",
    "            # wait for lock to free up before mutating jobs\n",
    "            time.sleep(1)\n",
    "        jobs_lock = True # lock jobs so other threads can't mutate it\n",
    "        \n",
    "        next_jobs = [j for j in jobs if j['status']=='incomplete'] # gather incomplete jobs\n",
    "        if(shuffle_jobs):\n",
    "            # randomize jobs. this way one machine doesn't get stuck trying to do the same job over and over (if it keeps failing)\n",
    "            random.shuffle(next_jobs)\n",
    "        if len(next_jobs):\n",
    "            my_job = next_jobs[0] # claim the next incomplete job\n",
    "            \n",
    "            # UPDATE JOB STATUS \n",
    "            my_job[\"status\"] = \"processing\"\n",
    "            my_job[\"host\"] = host\n",
    "            my_job[\"last_modified\"] = time.time()\n",
    "            \n",
    "            jobs_lock = False # free lock so other threads can mutate it\n",
    "            print \"Claimed job\"\n",
    "            print my_job\n",
    "        else:\n",
    "            jobs_lock = False \n",
    "            print \"No available jobs, but not all jobs complete. Wait just in case a job becomes available \"\n",
    "            # \n",
    "            time.sleep(30)\n",
    "            continue\n",
    "\n",
    "        try: \n",
    "            # Do job\n",
    "            doJob(my_job)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            # Success!\n",
    "            print \"Job success %s\" % (host)\n",
    "            print my_job\n",
    "            while(jobs_lock): time.sleep(1)\n",
    "            jobs_lock = True\n",
    "            my_job[\"status\"] = \"complete\"\n",
    "            my_job[\"last_modified\"] = time.time()\n",
    "            jobs_lock = False # free lock so other threads can mutate it\n",
    "            print \"Finished job\"\n",
    "            print my_job\n",
    "        except:\n",
    "            # Job failed. \n",
    "            raise\n",
    "            time.sleep(2)\n",
    "            print \"Job fail %s\" % (host)\n",
    "            print my_job\n",
    "            print sys.exc_info()\n",
    "            # Return job to \"incomplete\"\n",
    "            while(jobs_lock): time.sleep(1)\n",
    "            jobs_lock = True\n",
    "            my_job[\"status\"] = \"incomplete\"\n",
    "            my_job[\"last_modified\"] = time.time()\n",
    "            jobs_lock = False\n",
    "            #raise\n",
    "        \n",
    "    ### Thread Finished\n",
    "    # Terminate VM\n",
    "    \n",
    "    print \"Terminating %s...\" % host \n",
    "    vm.terminate()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Send local file to user@host:dir over scp \n",
    "def scpSend(file, user, host, dir):\n",
    "    for x in xrange(10): \n",
    "        # try 10 times to send file \n",
    "        try:\n",
    "            !scp -o \"StrictHostKeyChecking no\" \"{file}\" {user}@{host}:{dir}\n",
    "            break # success\n",
    "        except:\n",
    "            # file is probably in use by another thread, or my operating system\n",
    "            if(x<9):\n",
    "                pass\n",
    "            else:\n",
    "                print \"Failed to SCP file %s to %s\" % (file, host)\n",
    "                raise RunTimeError(\"Failed to SCP file %s to %s\" % (file, host)) # hm, fuck\n",
    "        time.sleep(5) # wait 5 seconds before trying again \n",
    "\n",
    "# awesome function that executes a string of commands (separated by new line) on user@host through ssh \n",
    "# remember to escape single quotes \n",
    "def sshx(commands, user, host):\n",
    "    commands = \"'\" + commands + \"'\"\n",
    "    tmpfile = \"__tmp.\" + str(random.randint(0,9999999)) + \".sh\"\n",
    "    !echo {commands} > {tmpfile}\n",
    "    time.sleep(1)\n",
    "    !cat {tmpfile}| ssh -o \"StrictHostKeyChecking no\" {user}@{host}\n",
    "    time.sleep(1)\n",
    "    !rm {tmpfile}\n",
    "    sys.stdin.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Debugging\n",
    "def doJob(job):\n",
    "    time.sleep(random.randint(10, 80))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Moves images to machine over scp, executes code over ssh, wget files back to local machine\n",
    "def doJob(job):\n",
    "    global user, num_iterations, image_size\n",
    "    host = job['host']\n",
    "    \n",
    "    # move images over to machine with scp\n",
    "    style_filename = basename(job['style'])\n",
    "    content_filename = basename(job['content'])\n",
    "    scpSend(job['style'], user, host, \"~/neural-style\")\n",
    "    scpSend(job['content'], user, host, \"~/neural-style\")\n",
    "    \n",
    "    # execute code \n",
    "    sshx(pathStuff+\"\\n\\\n",
    "cd ~/neural-style \\n\\\n",
    "rm output* \\n\\\n",
    "th neural_style.lua -num_iterations %s -style_image \\\"%s\\\" -content_image \\\"%s\\\" -image_size %s -backend cudnn -output_image output.png \\n\\\n",
    "tar -cvzf output.tar.gz output_* \\n\\\n",
    "\"%(num_iterations, style_filename,content_filename,image_size),user,host)\n",
    "    \n",
    "    # Save the output \n",
    "    # make dirs if they don't exist\n",
    "    !mkdir ./nn\n",
    "    !mkdir ./nn/archive\n",
    "    # wget the files over http, store locally\n",
    "    wget = !wget --tries=3 http://{host}/nn/neural-style/output.png -O \"./nn/{style_filename}_{content_filename}.png\"\n",
    "    # if output.png doesn't exist on the vm, raise exception\n",
    "    if(wgetFail(wget)):\n",
    "        !rm \"./nn/{style_filename}_{content_filename}.png\" # remove the blank file wget makes\n",
    "        raise RuntimeError(\"Neural style did not finish. No output.png was created.\")\n",
    "    wget = !wget --tries=3 http://{host}/nn/neural-style/output.tar.gz -O \"./nn/archive/{style_filename}_{content_filename}.tar.gz\"\n",
    "    if(wgetFail(wget)):\n",
    "        !rm \"./nn/archive/{style_filename}_{content_filename}.tar.gz\" # remove the blank file wget makes\n",
    "        raise RuntimeError(\"Failed to retrieve output.tar.gz\")\n",
    "\n",
    "# Returns true of output from !wget failed\n",
    "# Not sure if this would be different on different systems\n",
    "def wgetFail(wget):\n",
    "    return not (\"HTTP request sent, awaiting response... 200 OK\" in \"\\n\".join(wget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to set this pathStuff every time we send commands over SSH\n",
    "# bash loads different profiles when run non-interactively like this\n",
    "# See: http://stackoverflow.com/questions/415403/whats-the-difference-between-bashrc-bash-profile-and-environment\n",
    "# Alternatively these could have been set on the machine in the right profile before I made the image. \n",
    "pathStuff = \"\"\"\n",
    "export PATH=$PATH:/usr/local/cuda/bin\n",
    "export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH;\n",
    "\n",
    "# added by Anaconda 2.1.0 installer\n",
    "export PATH=\"/home/ubuntu/anaconda/bin:$PATH\"\n",
    "export PATH=~/torch-distro/install/bin:$PATH; export LD_LIBRARY_PATH=~/torch-distro/install/lib:$LD_LIBRARY_PATH;\n",
    "\n",
    "# Adding caffe to PYTHONPATH\n",
    "export PYTHONPATH=\"/home/ubuntu/caffe/python:$PYTHONPATH\"\n",
    "export PATH=/home/ubuntu/torch-distro/install/bin:$PATH  # Added automatically by torch-dist\n",
    "export LD_LIBRARY_PATH=/home/ubuntu/torch-distro/install/lib:$LD_LIBRARY_PATH  # Added automatically by torch-dist\n",
    "export DYLD_LIBRARY_PATH=/home/ubuntu/torch-distro/install/lib:$DYLD_LIBRARY_PATH  # Added automatically by torch-dist\n",
    "\n",
    "export LD_LIBRARY_PATH=/home/ubuntu/cudnn-6.5-linux-x64-v2-rc2:$LD_LIBRARY_PATH\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2')\n",
    "# Deploys a new EC2 instance of given machine_type (e.g. \"g2.2xlarge\"), returns id of new machine\n",
    "def deployVM(machine_type):\n",
    "    new_vm = ec2.create_instances(\n",
    "        ImageId = neuralstyle_ami,\n",
    "        MinCount = 1,\n",
    "        MaxCount = 1,\n",
    "        KeyName = 'exocortex2',\n",
    "        InstanceType = machine_type,\n",
    "        SecurityGroups = ['ssh-http']\n",
    "    )\n",
    "    print \"Creating new instance... %s\" % machine_type\n",
    "    return new_vm[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# VM image we start with\n",
    "# Everything is already installed on this AMI, it's ready to execute stuff\n",
    "neuralstyle_ami = \"ami-e095ca8a\"\n",
    "# If this no longer works, I have stopped paying to host this AMI. \n",
    "# Instead follow these instructions: https://gist.github.com/elad/e3a9e3cc609996b13454\n",
    "\n",
    "# m3.medium for debugging ($0.07/hour) \n",
    "#machine_type = 'm3.medium'\n",
    "# g2.2xlarge for real processing ($0.65/hour)\n",
    "machine_type = 'g2.2xlarge'\n",
    "\n",
    "# how many machines we deploy:\n",
    "number_of_vms = 4 # Double check your limit for the machine type. 10 is default. \n",
    "\n",
    "# how long do we run our VMs? Amazon EC2 bills you by rounding up to the hour. \n",
    "maximum_hours = 1\n",
    "# size of output image style transfer\n",
    "image_size = 400 # anything over 700 may cause GPU memory error\n",
    "# number of iterations of style transfer\n",
    "num_iterations = 400 \n",
    "\n",
    "# AWS machines use user \"ubuntu\"\n",
    "user = \"ubuntu\"\n",
    "# randomize jobs, this way if one machine keeps failing (example: not enough available memory)\n",
    "# it doesn't get stuck with the same job, and other machines will pick up those jobs instead\n",
    "shuffle_jobs = False\n",
    "# start time\n",
    "start_time = time.time()\n",
    "estimated_process_time = 4*60 # about n minutes per render \n",
    "termination_time = start_time + 60*60*maximum_hours\n",
    "termination_margin = 1.5*60 # give a margin of n minutes for shut down.\n",
    "\n",
    "jobs = [] # list of jobs \n",
    "jobs_lock = False # thread lock used when threads mutate jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_to_jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b2bc8f7d8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# PIZZAFIRE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0madd_to_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs/pizza.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inputs/FireLoop1_seq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'add_to_jobs' is not defined"
     ]
    }
   ],
   "source": [
    "### Applying Style Transfer to still image \n",
    "# add_to_jobs(\"inputs/style.png\", \"inputs/content.png\", False)\n",
    "\n",
    "### Applying Style Transfer to Video\n",
    "# Split video into individual frame images using VLC, Quicktime, etc. \n",
    "# Leave images in their own directory.\n",
    "# add_to_jobs(\"inputs/style.png\", \"inputs/video_frame_sequence\", True)\n",
    "\n",
    "### Applying Style Transfer to Large Images\n",
    "# You will likely run out of GPU memory if you want your output image to be larger than 800px * 800px. \n",
    "# Therefore, split a large content image into smaller slices, leave them in their own directory.\n",
    "# Use ImageSlicer.pynb to do this.\n",
    "# add_to_jobs(\"inputs/style.png\", \"inputs/large_image_slices\", True)\n",
    "\n",
    "# add_to_jobs(style, content, content_is_directory)\n",
    "# style = local image whose style we are transferring\n",
    "# content = local content image OR directory containing video frames\n",
    "# content_is_directory = True | False \n",
    "\n",
    "# PIZZAFIRE\n",
    "add_to_jobs(\"inputs/pizza.png\", \"inputs/FireLoop1_seq\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Machines, Execute Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DEPLOY instances first, then assign them threads.\n",
    "# If worker thread terminates for some reason, we can recover the instance and run a new worker\n",
    "vm_ids = []\n",
    "for i in xrange(number_of_vms):\n",
    "    # Deploy an AWS ec2 instance\n",
    "    vm_id = deployVM(machine_type)\n",
    "    vm_ids.append(vm_id)\n",
    "    print \"Deployed %s, %s\" % (machine_type, vm_id)\n",
    "\n",
    "# worker threads each own a machine, claim jobs, process jobs, and\n",
    "# terminate their machine when all jobs are done, before time limit\n",
    "workers = []\n",
    "for i in xrange(number_of_vms):\n",
    "    t = threading.Thread(target=worker, args=(i,vm_ids[i],))\n",
    "    workers.append(t)\n",
    "    t.start()\n",
    "\n",
    "# nanny thread double checks worker threads, terminates all VMs before time limit\n",
    "# this isn't necessary, but since processing costs $$, it's good to double check \n",
    "# Outputs status of jobs at end\n",
    "t = threading.Thread(target=nanny)\n",
    "t.start()\n",
    "\n",
    "# When finished, double check AWS console to make sure instances terminated.\n",
    "\n",
    "# If you stop this process or restart the kernel, you need to terminate the EC2 instances in the AWS console.\n",
    "# https://console.aws.amazon.com/ec2\n",
    "\n",
    "# Make animated gifs here: http://gifmaker.me/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
